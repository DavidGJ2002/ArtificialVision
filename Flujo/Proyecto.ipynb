{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3mSoeI4Y/aSgUpb8o0eLm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ap8HWzTIBEYf"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load a sample video from the web (replace with your own video URL)\n",
        "cap = cv2.VideoCapture('nofi006.mp4')\n",
        "\n",
        "# Parameters for corner detection\n",
        "feature_params = dict(maxCorners=500, qualityLevel=0.01, minDistance=10, blockSize=7)\n",
        "\n",
        "# Parameters for Lucas-Kanade optical flow\n",
        "lk_params = dict(winSize=(30, 30), maxLevel=5, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
        "\n",
        "# Create some random colors\n",
        "color = np.random.randint(0, 255, (500, 3))\n",
        "\n",
        "# Take the first frame and find corners in it\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
        "\n",
        "# Create a mask image for drawing purposes\n",
        "mask = np.zeros_like(old_frame)\n",
        "\n",
        "# Display the images in the notebook\n",
        "%matplotlib inline\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Calculate optical flow\n",
        "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
        "\n",
        "    # Select good points\n",
        "    good_new = p1[st == 1]\n",
        "    good_old = p0[st == 1]\n",
        "\n",
        "    # Draw the tracks\n",
        "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "        a, b = new.ravel()\n",
        "        c, d = old.ravel()\n",
        "\n",
        "        # Convert coordinates to integers\n",
        "        pt1 = (int(a), int(b))\n",
        "        pt2 = (int(c), int(d))\n",
        "\n",
        "        mask = cv2.line(mask, pt1, pt2, color[i].tolist(), 2)\n",
        "        frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
        "\n",
        "    # Combine the frame with the mask for visualization\n",
        "    optical_flow_result = cv2.add(frame, mask)\n",
        "\n",
        "    # Display the optical flow result using cv2_imshow\n",
        "    cv2_imshow(optical_flow_result)\n",
        "\n",
        "    # Apply adaptive thresholding for segmentation\n",
        "    thresholded = cv2.adaptiveThreshold(frame_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "\n",
        "    # Display the segmented frame using cv2_imshow\n",
        "    cv2_imshow(thresholded)\n",
        "\n",
        "    k = cv2.waitKey(25)\n",
        "    if k == 27:\n",
        "        break\n",
        "\n",
        "    # Update the previous frame and points\n",
        "    old_gray = frame_gray.copy()\n",
        "    p0 = good_new.reshape(-1, 1, 2)\n",
        "\n",
        "# Release the video capture object\n",
        "cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "# The video feed is read in as\n",
        "# a VideoCapture object\n",
        "cap = cv.VideoCapture(\"nofi006.mp4\")\n",
        "\n",
        "# ret = a boolean return value from\n",
        "# getting the frame, first_frame = the\n",
        "# first frame in the entire video sequence\n",
        "ret, first_frame = cap.read()\n",
        "\n",
        "# Converts frame to grayscale because we\n",
        "# only need the luminance channel for\n",
        "# detecting edges - less computationally\n",
        "# expensive\n",
        "prev_gray = cv.cvtColor(first_frame, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "# Creates an image filled with zero\n",
        "# intensities with the same dimensions\n",
        "# as the frame\n",
        "mask = np.zeros_like(first_frame)\n",
        "\n",
        "# Sets image saturation to maximum\n",
        "mask[..., 1] = 255\n",
        "\n",
        "while cap.isOpened():\n",
        "    # ret = a boolean return value from getting\n",
        "    # the frame, frame = the current frame being\n",
        "    # projected in the video\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Check if the frame was read successfully\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Converts each frame to grayscale\n",
        "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Calculates dense optical flow by Farneback method with adjusted parameters\n",
        "    flow = cv.calcOpticalFlowFarneback(prev_gray, gray,\n",
        "                                       None,\n",
        "                                       pyr_scale=0.5,   # Adjust the image scale\n",
        "                                       levels=3,\n",
        "                                       winsize=15,\n",
        "                                       iterations=3,\n",
        "                                       poly_n=5,\n",
        "                                       poly_sigma=1.1,   # Adjust the standard deviation of the Gaussian\n",
        "                                       flags=0)\n",
        "\n",
        "    # Computes the magnitude and angle of the 2D vectors\n",
        "    magnitude, angle = cv.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "\n",
        "    # Sets image hue according to the optical flow\n",
        "    # direction\n",
        "    mask[..., 0] = angle * 180 / np.pi / 2\n",
        "\n",
        "    # Sets image value according to the optical flow\n",
        "    # magnitude (normalized)\n",
        "    mask[..., 2] = cv.normalize(magnitude, None, 0, 255, cv.NORM_MINMAX)\n",
        "\n",
        "    # Converts HSV to RGB (BGR) color representation\n",
        "    rgb = cv.cvtColor(mask, cv.COLOR_HSV2BGR)\n",
        "\n",
        "    # Convert the frame to grayscale for adaptive thresholding\n",
        "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Adaptive Thresholding for segmentation\n",
        "    thresholded = cv.adaptiveThreshold(gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 11, 2)\n",
        "\n",
        "    # Combine the original frame with the segmented result\n",
        "    segmented = cv.bitwise_and(frame, frame, mask=thresholded)\n",
        "\n",
        "    # Concatenate the frames horizontally for display\n",
        "    display_frame = np.concatenate((frame, rgb, segmented), axis=1)\n",
        "\n",
        "    # Display the concatenated frame\n",
        "    cv2_imshow(display_frame)\n",
        "\n",
        "    # Breaks out of the loop when the user presses the 'q' key\n",
        "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "    # Updates previous frame\n",
        "    prev_gray = gray\n",
        "\n",
        "# Releases resources and closes all windows\n",
        "cap.release()\n",
        "cv.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "orTCiLORBJeX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}